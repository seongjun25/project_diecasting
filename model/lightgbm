# lightGBM

import pandas as pd
import numpy as np

from sklearn.impute import KNNImputer, SimpleImputer
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# -------------------
# 0) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° & ì „ì²˜ë¦¬
# -------------------
df = pd.read_csv("./data/train.csv")

# ì´ìƒì¹˜/ê²°ì¸¡ í–‰ ì œê±°
df = df.drop(index=19327) 
df = df.drop(index=[6000,11811,17598]) 
df = df.drop(index=[46546])
df = df.drop(index=list(df[df['Coolant_temperature'] == 1449].index))
df = df.drop(index=list(df[df['upper_mold_temp1'] == 1449].index))
df = df.drop(index=list(df[df['upper_mold_temp2'] == 4232].index))

# ì‹œê°„ ë³€ìˆ˜ ê°€ê³µ
df['registration_time'] = pd.to_datetime(df['registration_time'])
df['hour'] = df['registration_time'].dt.hour.astype(object)

# ê²°ì¸¡ì¹˜ ë³´ì •
df['tryshot_signal'] = df['tryshot_signal'].fillna('A')
df['molten_volume'] = df['molten_volume'].fillna(0)
condition = (df['molten_volume'].notna()) & (df['heating_furnace'].isna())
df.loc[condition, 'heating_furnace'] = 'C'

# íƒ€ì… ë³€ê²½
df["mold_code"] = df["mold_code"].astype(object)
df["EMS_operation_time"] = df["EMS_operation_time"].astype(object)

# ê°’ ì¡°ê±´ ê¸°ë°˜ ê²°ì¸¡ ì²˜ë¦¬
df.loc[df["molten_temp"] <= 80, "molten_temp"] = np.nan
df.loc[df["physical_strength"] <= 5, "physical_strength"] = np.nan

# ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
df = df.drop(columns=[
    'id','line','name','mold_name','emergency_stop','time','date','registration_time',
    'upper_mold_temp3','lower_mold_temp3','working'
])
df.info()

df.to_csv("train_df.csv")
# -------------------
# 1) X, y ë¶„ë¦¬
# -------------------
y = df['passorfail']
X = df.drop(columns=['passorfail'])

# ì‹œê°„ ìˆœì„œ ê¸°ì¤€ìœ¼ë¡œ split 
split_point = int(len(df) * 0.8)
X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]

# -------------------
# 2) ìˆ˜ì¹˜/ë²”ì£¼í˜• ì»¬ëŸ¼ ë¶„ë¦¬
# -------------------
num_cols = X.select_dtypes(include=['int64','float64']).columns
cat_cols = X.select_dtypes(include=['object']).columns

# -------------------
# 3) ì „ì²˜ë¦¬ê¸° ì •ì˜
# -------------------
# ìˆ˜ì¹˜í˜•: KNNìœ¼ë¡œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°
num_transformer = Pipeline(steps=[
    ('imputer', KNNImputer(n_neighbors=5)),
    ('scaler', RobustScaler())
])

# ë²”ì£¼í˜•: ìµœë¹ˆê°’ + OrdinalEncoder
cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))
])

# ColumnTransformerë¡œ í•©ì¹˜ê¸°
# preprocessor = ColumnTransformer(
#     transformers=[
#         ('num', num_transformer, num_cols),
#         ('cat', cat_transformer, cat_cols)
#     ]
# )


preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_transformer, num_cols),
        ('cat', cat_transformer, cat_cols)
    ],
    verbose_feature_names_out=False   # ğŸ‘ˆ prefix ì œê±°
)




# -------------------
# 4) LightGBM ëª¨ë¸
# -------------------
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LGBMClassifier(random_state=42))
])




# -------------------
# 5) í•™ìŠµ & í‰ê°€
# -------------------
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

# Classification Report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# ROC-AUC
print("ROC-AUC:", roc_auc_score(y_test, y_prob))

# Confusion Matrix ì‹œê°í™”
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["Pred 0","Pred 1"],
            yticklabels=["True 0","True 1"])
plt.title("Confusion Matrix")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()


import optuna
from sklearn.metrics import roc_auc_score

def objective(trial):
    params = {
    "num_leaves": trial.suggest_int("num_leaves", 16, 256),
    "max_depth": trial.suggest_int("max_depth", 3, 12),
    "learning_rate": trial.suggest_float("learning_rate", 1e-3, 0.3, log=True),
    "n_estimators": trial.suggest_int("n_estimators", 100, 1000),
    "subsample": trial.suggest_float("subsample", 0.6, 1.0),
    "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0),
    "min_child_samples": trial.suggest_int("min_child_samples", 5, 100),
    "scale_pos_weight": (len(y_train) - y_train.sum()) / y_train.sum(),
    "min_gain_to_split": 0.0   # ë¶„í•  í—ˆìš©ì„ ë” ëŠìŠ¨í•˜ê²Œ
}


    model = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', LGBMClassifier(random_state=42, **params))
    ])
    model.fit(X_train, y_train)
    y_prob = model.predict_proba(X_test)[:, 1]
    return roc_auc_score(y_test, y_prob)

# ì‹¤í–‰
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=30, show_progress_bar=True)

print("Best Trial:")
best_trial = study.best_trial
print("ROC-AUC:", best_trial.value)
print("Best Params:", best_trial.params)


best_trial={'num_leaves': 98, 'max_depth': 9, 'learning_rate': 0.008275183434186801, 'n_estimators': 677, 'subsample': 0.6035915042464275, 'colsample_bytree': 0.879104309394895, 'min_child_samples': 85,
            'scale_pos_weight':21.583812811660913}


# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ ì¬í•™ìŠµ
final_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LGBMClassifier(random_state=42, **best_trial))
])
final_model.fit(X_train, y_train)

# ìµœì¢… feature ì´ë¦„ í™•ì¸
feature_names = final_model.named_steps['preprocessor'].get_feature_names_out()
print(feature_names)
